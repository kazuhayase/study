{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a777c57e-41e6-4237-9044-cdc972ba5237",
   "metadata": {
    "collapsed": false,
    "id": "mngcLLyWrbcC",
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /home/kazu/venv/lib/python3.11/site-packages (0.109.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/kazu/venv/lib/python3.11/site-packages (from fastapi) (2.6.1)\r\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/kazu/venv/lib/python3.11/site-packages (from fastapi) (0.36.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kazu/venv/lib/python3.11/site-packages (from fastapi) (4.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.2)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from starlette<0.37.0,>=0.36.3->fastapi) (4.2.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/kazu/venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (3.6)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/kazu/venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uvicorn in /home/kazu/venv/lib/python3.11/site-packages (0.27.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click>=7.0 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn) (8.1.7)\r\n",
      "Requirement already satisfied: h11>=0.8 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn) (0.14.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.7/1.8 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex>=2022.1.18\r\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/785.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /home/kazu/venv/lib/python3.11/site-packages (from tiktoken) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.2.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: regex, tiktoken\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed regex-2023.12.25 tiktoken-0.6.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m174.1/226.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/226.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /home/kazu/venv/lib/python3.11/site-packages (from openai) (4.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting distro<2,>=1.7.0\r\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpx<1,>=0.23.0\r\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /home/kazu/venv/lib/python3.11/site-packages (from openai) (2.6.1)\r\n",
      "Requirement already satisfied: sniffio in /home/kazu/venv/lib/python3.11/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/kazu/venv/lib/python3.11/site-packages (from openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/kazu/venv/lib/python3.11/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/kazu/venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: certifi in /home/kazu/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpcore==1.*\r\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /home/kazu/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: httpcore, distro, httpx, openai\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed distro-1.9.0 httpcore-1.0.2 httpx-0.26.0 openai-1.12.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core<0.2,>=0.1.16\r\n",
      "  Downloading langchain_core-0.1.22-py3-none-any.whl (239 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m194.6/239.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-openai) (1.26.4)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-openai) (1.12.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken<0.6.0,>=0.5.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/2.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML>=5.3 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (4.2.0)\r\n",
      "Collecting jsonpatch<2.0,>=1.33\r\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langsmith<0.0.88,>=0.0.87\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.6.1)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/kazu/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/kazu/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\r\n",
      "Requirement already satisfied: sniffio in /home/kazu/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/kazu/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/kazu/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/kazu/venv/lib/python3.11/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna>=2.8 in /home/kazu/venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.6)\r\n",
      "Requirement already satisfied: certifi in /home/kazu/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/kazu/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/kazu/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonpointer>=1.9\r\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (2.16.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: jsonpointer, tiktoken, jsonpatch, langsmith, langchain-core, langchain-openai\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: tiktoken\r\n",
      "    Found existing installation: tiktoken 0.6.0\r\n",
      "    Uninstalling tiktoken-0.6.0:\r\n",
      "      Successfully uninstalled tiktoken-0.6.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.22 langchain-openai-0.0.5 langsmith-0.0.87 tiktoken-0.5.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaleido\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/79.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/79.9 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:17\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/79.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/79.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/79.9 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/79.9 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/79.9 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/79.9 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/79.9 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/79.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/79.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.4/79.9 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.4/79.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/79.9 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/79.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.9/79.9 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/79.9 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/79.9 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.1/79.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.3/79.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/79.9 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/79.9 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/79.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/79.9 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/79.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/79.9 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/79.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/79.9 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/79.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/79.9 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m56.9/79.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m59.1/79.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m61.2/79.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m63.2/79.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m64.8/79.9 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m66.1/79.9 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m66.1/79.9 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m66.5/79.9 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m68.5/79.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m70.6/79.9 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m72.7/79.9 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m74.7/79.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m76.5/79.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m78.7/79.9 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: kaleido\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed kaleido-0.2.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-multipart\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: python-multipart\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed python-multipart-0.0.9\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading cohere-4.46-py3-none-any.whl (52 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m51.2/52.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m51.2/52.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m505.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp<4.0,>=3.0\r\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: backoff<3.0,>=2.0 in /home/kazu/venv/lib/python3.11/site-packages (from cohere) (2.2.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastavro<2.0,>=1.8\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading fastavro-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/3.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m2.5/3.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m3.1/3.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m3.1/3.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m3.1/3.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m3.1/3.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m3.1/3.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /home/kazu/venv/lib/python3.11/site-packages (from cohere) (6.11.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /home/kazu/venv/lib/python3.11/site-packages (from cohere) (2.31.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/kazu/venv/lib/python3.11/site-packages (from cohere) (2.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiosignal>=1.1.2\r\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting attrs>=17.3.0\r\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frozenlist>=1.1.1\r\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/272.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting multidict<7.0,>=4.5\r\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/128.7 kB\u001b[0m \u001b[31m161.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yarl<2.0,>=1.0\r\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/328.1 kB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/kazu/venv/lib/python3.11/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: multidict, frozenlist, fastavro, attrs, yarl, aiosignal, aiohttp, cohere\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 attrs-23.2.0 cohere-4.46 fastavro-1.9.3 frozenlist-1.4.1 multidict-6.0.5 yarl-1.9.4\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading langchain-0.1.6-py3-none-any.whl (811 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/811.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/811.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/811.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/811.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/811.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML>=5.3 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (6.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SQLAlchemy<3,>=1.4\r\n",
      "  Downloading SQLAlchemy-2.0.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/3.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/3.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/3.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (3.9.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataclasses-json<0.7,>=0.5.7\r\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (1.33)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community<0.1,>=0.0.18\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.2/1.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.2,>=0.1.22 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (0.1.22)\r\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (0.0.87)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (2.6.1)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/kazu/venv/lib/python3.11/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kazu/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kazu/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kazu/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kazu/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kazu/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting marshmallow<4.0.0,>=3.18.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing-inspect<1,>=0.4.0\r\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/kazu/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio<5,>=3 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.2.0)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/kazu/venv/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kazu/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting greenlet!=0.4.17\r\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/620.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m614.4/620.0 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.0/620.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sniffio>=1.1 in /home/kazu/venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mypy-extensions>=0.3.0\r\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: mypy-extensions, marshmallow, greenlet, typing-inspect, SQLAlchemy, dataclasses-json, langchain-community, langchain\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed SQLAlchemy-2.0.25 dataclasses-json-0.6.4 greenlet-3.0.3 langchain-0.1.6 langchain-community-0.0.19 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/284.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/284.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m276.5/284.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pypdf\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed pypdf-4.0.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /home/kazu/venv/lib/python3.11/site-packages (0.4.22)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: build>=1.0.3 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.0.3)\r\n",
      "Requirement already satisfied: requests>=2.28 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (2.6.1)\r\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.7.3)\r\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.109.2)\r\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.27.1)\r\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.26.4)\r\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (3.4.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (4.9.0)\r\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (3.4.0)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.43b0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.15.1)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.48.9)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (4.66.2)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (6.1.1)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (1.60.1)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (4.1.2)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (0.9.0)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (29.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (8.2.3)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (6.0.1)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/kazu/venv/lib/python3.11/site-packages (from chromadb) (4.1.0)\r\n",
      "Requirement already satisfied: packaging>=19.0 in /home/kazu/venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\r\n",
      "Requirement already satisfied: pyproject_hooks in /home/kazu/venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.0.0)\r\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/kazu/venv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=14.05.14 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/kazu/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.0)\r\n",
      "Requirement already satisfied: coloredlogs in /home/kazu/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in /home/kazu/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in /home/kazu/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.2)\r\n",
      "Requirement already satisfied: sympy in /home/kazu/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\r\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\r\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\r\n",
      "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (66.1.1)\r\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/kazu/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monotonic>=1.5 in /home/kazu/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/kazu/venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.16.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.3.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\r\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/kazu/venv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/kazu/venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h11>=0.8 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /home/kazu/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kazu/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kazu/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kazu/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /home/kazu/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kazu/venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/kazu/venv/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/kazu/venv/lib/python3.11/site-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (4.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: humanfriendly>=9.1 in /home/kazu/venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath>=0.19 in /home/kazu/venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sniffio>=1.1 in /home/kazu/venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/kazu/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[sentencepiece]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/8.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/8.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/8.4 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/8.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/8.4 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m7.4/8.4 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.15.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting safetensors>=0.4.1\r\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (4.66.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece!=0.1.92,>=0.1.91\r\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/kazu/venv/lib/python3.11/site-packages (from transformers[sentencepiece]) (4.25.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kazu/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kazu/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (4.9.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kazu/venv/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kazu/venv/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (2.2.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kazu/venv/lib/python3.11/site-packages (from requests->transformers[sentencepiece]) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: sentencepiece, safetensors, transformers\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed safetensors-0.4.2 sentencepiece-0.1.99 transformers-4.37.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colab\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading colab-1.13.5.tar.gz (567 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/567.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/567.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.7/567.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting Django<1.8,>=1.7.10\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading Django-1.7.11-py2.py3-none-any.whl (7.4 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/7.4 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/7.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/7.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/7.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/7.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/7.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/7.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/7.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m5.4/7.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m6.3/7.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m6.3/7.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m6.3/7.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m6.3/7.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m6.3/7.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m6.3/7.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m6.9/7.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Whoosh>=2.7.0\r\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/468.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting celery[redis]>=3.1.2\r\n",
      "  Downloading celery-5.3.6-py3-none-any.whl (422 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.0/422.0 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting chardet>=2.3.0\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/199.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting django-haystack>=2.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django-haystack-3.2.1.tar.gz (466 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/466.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.6/466.6 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting django-hitcounter>=0.1.1\r\n",
      "  Downloading django-hitcounter-0.1.1.tar.gz (3.1 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting django-revproxy[diazo]>=0.9.9\r\n",
      "  Downloading django_revproxy-0.12.0-py3-none-any.whl (18 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting django-taggit>=0.12.1\r\n",
      "  Downloading django_taggit-5.0.1-py3-none-any.whl (61 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting etiquetando==0.1\r\n",
      "  Downloading etiquetando-0.1.tar.gz (259 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/259.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting html2text>=3.200.3\r\n",
      "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytz>=2011n\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/505.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /home/kazu/venv/lib/python3.11/site-packages (from colab) (2.31.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting repoze.lru>=0.6\r\n",
      "  Downloading repoze.lru-0.7-py3-none-any.whl (10 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stemming>=1.0\r\n",
      "  Downloading stemming-1.0.1.zip (13 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting billiard<5.0,>=4.2.0\r\n",
      "  Downloading billiard-4.2.0-py3-none-any.whl (86 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting click-didyoumean>=0.3.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading click_didyoumean-0.3.0-py3-none-any.whl (2.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting click-plugins>=1.1.1\r\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting click-repl>=0.2.0\r\n",
      "  Downloading click_repl-0.3.0-py3-none-any.whl (10 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0,>=8.1.2 in /home/kazu/venv/lib/python3.11/site-packages (from celery[redis]>=3.1.2->colab) (8.1.7)\r\n",
      "Collecting kombu<6.0,>=5.3.4\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading kombu-5.3.5-py3-none-any.whl (200 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/200.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.0/200.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/kazu/venv/lib/python3.11/site-packages (from celery[redis]>=3.1.2->colab) (2.8.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tzdata>=2022.7\r\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/346.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vine<6.0,>=5.1.0\r\n",
      "  Downloading vine-5.1.0-py3-none-any.whl (9.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis!=4.5.5,<6.0.0,>=4.5.2\r\n",
      "  Downloading redis-5.0.1-py3-none-any.whl (250 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/250.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting django-haystack>=2.2\r\n",
      "  Downloading django-haystack-3.2.0.tar.gz (466 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/466.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.5/466.5 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Downloading django_haystack-3.1.1-py3-none-any.whl (141 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/141.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.5/141.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading django_haystack-3.1.0-py3-none-any.whl (141 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/141.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.5/141.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading django-haystack-3.0.tar.gz (450 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/450.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Downloading django-haystack-2.8.1.tar.gz (1.6 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.5/1.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Downloading django-haystack-2.8.0.tar.gz (425 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/425.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.5/425.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Downloading django-haystack-2.7.0.tar.gz (1.6 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.5/1.6 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Downloading django-haystack-2.6.1.tar.gz (383 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/383.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.9/383.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Downloading django-haystack-2.6.0.tar.gz (1.4 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Downloading django-haystack-2.5.1.tar.gz (212 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/212.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Downloading django-haystack-2.5.0.tar.gz (212 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/212.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Downloading django-haystack-2.4.1.tar.gz (160 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting django-revproxy[diazo]>=0.9.9\r\n",
      "  Downloading django_revproxy-0.11.0-py3-none-any.whl (18 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_revproxy-0.10.0-py3-none-any.whl (17 kB)\r\n",
      "Requirement already satisfied: urllib3>=1.12 in /home/kazu/venv/lib/python3.11/site-packages (from django-revproxy[diazo]>=0.9.9->colab) (2.2.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diazo>=1.0.5\r\n",
      "  Downloading diazo-1.5.0-py2.py3-none-any.whl (309 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml>=3.4\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.1 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/8.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/8.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/8.1 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m6.3/8.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting django-taggit>=0.12.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-4.0.0-py3-none-any.whl (60 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-3.1.0-py3-none-any.whl (60 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-3.0.0-py3-none-any.whl (59 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading django_taggit-2.1.0-py3-none-any.whl (59 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-2.0.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-1.5.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading django_taggit-1.5.0-py3-none-any.whl (52 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-1.4.0-py3-none-any.whl (46 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-1.3.0-py3-none-any.whl (45 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-1.2.0-py3-none-any.whl (45 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-1.1.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading django_taggit-1.0.0-py3-none-any.whl (42 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-0.24.0-py2.py3-none-any.whl (42 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading django_taggit-0.23.0-py2.py3-none-any.whl (44 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading django_taggit-0.22.2-py2.py3-none-any.whl (45 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.7.0->colab) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.7.0->colab) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kazu/venv/lib/python3.11/site-packages (from requests>=2.7.0->colab) (2024.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prompt-toolkit>=3.0.36\r\n",
      "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/386.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting cssselect\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: six in /home/kazu/venv/lib/python3.11/site-packages (from diazo>=1.0.5->django-revproxy[diazo]>=0.9.9->colab) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting amqp<6.0.0,>=5.1.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading amqp-5.2.0-py3-none-any.whl (50 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting async-timeout>=4.0.2\r\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wcwidth\r\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: Whoosh, wcwidth, stemming, repoze.lru, pytz, django-taggit, django-hitcounter, Django, vine, tzdata, prompt-toolkit, lxml, html2text, etiquetando, django-revproxy, django-haystack, cssselect, click-plugins, click-didyoumean, chardet, billiard, async-timeout, redis, diazo, click-repl, amqp, kombu, celery, colab\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: stemming is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py install for stemming ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: django-hitcounter is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Running setup.py install for django-hitcounter ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: etiquetando is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Running setup.py install for etiquetando ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: django-haystack is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Running setup.py install for django-haystack ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: colab is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Running setup.py install for colab ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hSuccessfully installed Django-1.7.11 Whoosh-2.7.4 amqp-5.2.0 async-timeout-4.0.3 billiard-4.2.0 celery-5.3.6 chardet-5.2.0 click-didyoumean-0.3.0 click-plugins-1.1.1 click-repl-0.3.0 colab-1.13.5 cssselect-1.2.0 diazo-1.5.0 django-haystack-2.4.1 django-hitcounter-0.1.1 django-revproxy-0.10.0 django-taggit-0.22.2 etiquetando-0.1 html2text-2020.1.16 kombu-5.3.5 lxml-5.1.0 prompt-toolkit-3.0.43 pytz-2024.1 redis-5.0.1 repoze.lru-0.7 stemming-1.0.1 tzdata-2023.4 vine-5.1.0 wcwidth-0.2.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U fastapi\n",
    "!pip install -U uvicorn\n",
    "!pip install -U tiktoken\n",
    "!pip install -U openai\n",
    "!pip install -U langchain-openai\n",
    "!pip install -U kaleido\n",
    "!pip install -U python-multipart\n",
    "!pip install -U cohere\n",
    "!pip install -U langchain\n",
    "!pip install -U pypdf\n",
    "!pip install -U chromadb\n",
    "!pip install -U 'transformers[sentencepiece]'\n",
    "#!pip install -U google.colab\n",
    "!pip install -U colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01989d5b-8b30-4029-805a-4d0d54fb00d4",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "IuNebGEUDuwy",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "3fa9f0e6-75dc-4cf2-fbcf-b209fc3571cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***エージェントが要約を実行***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: 変額年金についての情報は、指定されたテキストファイル「hoken1.txt」から探す必要があります。まずは、変額年金に関連する内容を見つけることから始めます。\n",
      "Action: vec_search\n",
      "Action Input: 変額年金\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m変額年金は、投資の成果に基づいてその受け取り額が変動する年金商品です。具体的には、加入者が支払った保険料を基に、株式や債券などの投資先に資金を運用し、その運用成果に応じて年金額が増減します。運用結果が良ければ受け取り年金額が増える可能性がありますが、逆に運用結果が悪ければ受け取り額が減少するリスクもあります。\n",
      "\n",
      "変額年金には、最低保証機能を持つものもあります。これは、投資の結果が悪くても、契約時に定められた最低限の年金額は保証されるというものです。これにより、投資リスクをある程度抑えることが可能です。\n",
      "\n",
      "また、変額年金には様々な種類があります。例えば、途中で引き出しを行えるタイプや、一定期間後に年金を受け取るタイプなど、多様なニーズに応える商品が提供されています。選択する商品によって、運用方針やリスクの度合い、手数料などが異なるため、加入前には詳細な商品説明を受け、自身のリスク許容度や将来設計に合った商品を選ぶことが重要です。\n",
      "\n",
      "変額年金は、長期的な資産形成や将来の年金受給を目的とした商品であり、加入する際には、投資リスクや運用成果に大きく左右される点を十分に理解し、慎重な判断が求められます。\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 変額年金は投資成果により受取額が変動する年金商品。加入者の保険料を株式や債券に運用し、運用成果に応じ年金額が増減。最低保証機能があり、投資リスクを抑えることが可能。商品には多様な種類があり、リスク許容度や将来設計に合った選択が重要。投資リスクへの理解と慎重な判断が求められる。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "変額年金は投資成果により受取額が変動する年金商品。加入者の保険料を株式や債券に運用し、運用成果に応じ年金額が増減。最低保証機能があり、投資リスクを抑えることが可能。商品には多様な種類があり、リスク許容度や将来設計に合った選択が重要。投資リスクへの理解と慎重な判断が求められる。\n",
      "\n",
      "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
      "> "
     ]
    }
   ],
   "source": [
    "# 環境変数の準備\n",
    "import os\n",
    "import logging\n",
    "\n",
    "### Google Colab\n",
    "#from google.colab import userdata\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "\n",
    "#import sys\n",
    "#todo logger設定の高度化\n",
    "#https://kewton.blog/archives/1350\n",
    "logging.basicConfig(\n",
    "    filename=\"app.log\",\n",
    "    #stream=sys.stdout,\n",
    "    level=logging.INFO, #ERROR, WARNING, INFO, DEBUG\n",
    "    format=\"[%(process)d-%(thread)d]-%(asctime)s-[%(filename)s:%(lineno)d]-%(levelname)s-%(message)s\",\n",
    "    force=True)\n",
    "\n",
    "### Google Colab\n",
    "##g_secret ='act_openai'\n",
    "#g_secret ='kazu_act_openai'\n",
    "##g_secret ='OPENAI_API_KEY'\n",
    "#logging.info(f'secret = {g_secret}')\n",
    "#os.environ[\"OPENAI_API_KEY\"] = userdata.get(g_secret)\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "import tiktoken\n",
    "## Deprecated\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def _input(prompt):\n",
    "    print(prompt, end='', flush=True)\n",
    "    #s = sys.stdin.buffer.readline()\n",
    "    s = input()\n",
    "#    s = s.decode('utf-8') \\\n",
    "    s = s.replace(\"\\r\", \"\") \\\n",
    "         .replace(\"\\n\", \"\")\n",
    "    return s\n",
    "\n",
    "# 公式のExampleを参考にしたプロンプト組み立て関数\n",
    "def make_prompt(log):\n",
    "    prompt = [\n",
    "        f\"{uttr['speaker']}: {uttr['text']}\"\n",
    "        for uttr in log\n",
    "    ]\n",
    "    prompt = \"<NL>\".join(prompt)\n",
    "    return prompt\n",
    "\n",
    "# 対話については辞書で持っておくようにする\n",
    "def add_log(log, role, text):\n",
    "    log.append({\n",
    "        \"speaker\": role,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "k = 40\n",
    "#max_length = 128\n",
    "max_length = 15\n",
    "\n",
    "\n",
    "# ちょっとずつ結果を出力してくれるジェネレータ。ChatGPTに聞きました、後述\n",
    "def gradually_generate(model, tokenizer, token_ids, max_length):\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(token_ids.to(model.device))\n",
    "\n",
    "        logits = outputs.logits\n",
    "        indices_to_remove = logits < torch.topk(logits, k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = float('-inf')\n",
    "        probs = torch.nn.functional.softmax(logits[..., -1, :], dim=-1)\n",
    "        next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "        token_ids = torch.cat((token_ids, next_token_id), dim=-1)\n",
    "\n",
    "        output_str = tokenizer.decode(next_token_id[0])\n",
    "\n",
    "        yield output_str.replace(\"<NL>\", \"\\n\")\n",
    "\n",
    "        if \"</s>\" in output_str:\n",
    "            break\n",
    "\n",
    "\n",
    "# https://qiita.com/Isaka-code/items/f45a9a8288710aa807d9\n",
    "# 【2023年12月最新】LangChainを用いてPDFから演習問題を抽出する方法【RAG】\n",
    "## メインの処理\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #file_path = \"hoken1-ch1.txt\"\n",
    "    #file_path = \"/content/drive/MyDrive/simple.txt\"\n",
    "    #file_path = \"/content/drive/MyDrive/Actuary/eBooks/hoken1-ch1.txt\"\n",
    "    ###file_path = \"/content/drive/MyDrive/Actuary/eBooks/hoken1.txt\"\n",
    "    file_path = \"/home/kazu/Books/Actuary-ebook/hoken1.txt\" ## Ubuntu@lavie\n",
    "\n",
    "    # 1. PDFを読み込む\n",
    "    #todo PDF読み込みはPyPDFではエラーになる。javascriptは読み込めた（はず）が、処理がうまくいかなかったので、テキストに変換して処理している。\n",
    "    #pages = PyPDFLoader(file_path).load()\n",
    "    pages = TextLoader(file_path).load()\n",
    "\n",
    "    # 2. ドキュメントをチャンクに分割\n",
    "    #docs = CharacterTextSplitter(chunk_size=5000, chunk_overlap=0).split_documents(pages)\n",
    "    docs = CharacterTextSplitter().split_documents(pages)\n",
    "    logging.info(f\"#docs = {len(docs)}\") # 抽出したドキュメントの数\n",
    "\n",
    "    # 3. 埋め込みモデルの初期化\n",
    "    ### open ai の embeddingがupgrade\n",
    "    #https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
    "    #text-embedding-ada-002 -> text-embedding-3-{small,large}\n",
    "\n",
    "    # models\n",
    "    #todo 3.5-turboではtoken数が超過するというエラーを回避する必要がある。\n",
    "    #GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "    #GPT_MODEL = \"gpt-4-1106-preview\"\n",
    "    GPT_MODEL = \"gpt-4-turbo-preview\"\n",
    "    #EMBEDDING_MODEL = 'text-embedding-ada-002'\n",
    "    EMBEDDING_MODEL = 'text-embedding-3-small'\n",
    "    #EMBEDDING_MODEL = 'text-embedding-3-large'\n",
    "\n",
    "    logging.info(f\"GPT_MODEL = {GPT_MODEL}\")\n",
    "    logging.info(f\"EMBEDDING_MODEL = {EMBEDDING_MODEL}\")\n",
    "    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL,tiktoken_model_name=\"cl100k_base\")\n",
    "    #embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "    #embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    ### todo; 他のEmbeddingも検証してみたい\n",
    "\n",
    "    # https://qiita.com/akeyhero/items/ce371bfed64399027c23\n",
    "    # https://huggingface.co/intfloat/multilingual-e5-large\n",
    "    # https://huggingface.co/Cohere/Cohere-embed-multilingual-v3.0\n",
    "\n",
    "\n",
    "    # 4. ベクトルストアにドキュメントを格納\n",
    "    # todo ChromaDB 永続化\n",
    "    retriever = Chroma.from_documents(docs, embeddings).as_retriever()\n",
    "\n",
    "    while \"[exit]\" not in (keyword := _input(\"\\n保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\\n> \")):\n",
    "      retrieval_query = keyword + \"に関わる箇所を抽出してください。\"\n",
    "      question = keyword + \"に関わる箇所を1つ選択して100字程度に要約してください。\"\n",
    "\n",
    "      prompt_template_qa = \"\"\"あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\n",
    "      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\n",
    "      に答えてください。\n",
    "\n",
    "      {context}\n",
    "\n",
    "      質問: {question}\n",
    "      回答（日本語）:\"\"\"\n",
    "\n",
    "      prompt_qa = PromptTemplate(\n",
    "        template=prompt_template_qa,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "      )\n",
    "      chain_type_kwargs = {\"prompt\": prompt_qa}\n",
    "\n",
    "      logging.info(f\"retrieval_query = {retrieval_query}\")\n",
    "      logging.info(f\"question = {question}\")\n",
    "      logging.info(f\"prompt_qa = {prompt_qa}\")\n",
    "      logging.info(f\"chain_type_kwargs = {chain_type_kwargs}\")\n",
    "\n",
    "      # 5. ドキュメントを抽出\n",
    "      context_docs = retriever.get_relevant_documents(retrieval_query)\n",
    "      logging.info(f\"#context_docs = {len(context_docs)}\") # 抽出したドキュメントの数\n",
    "      encoding = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "      str_docs=''\n",
    "      for doc in context_docs:\n",
    "        str_docs = ' '.join(doc.page_content)\n",
    "      logging.info(f\"#tokens_context_docs = {len(encoding.encode(str_docs))}\") # 抽出したドキュメントのtoken数\n",
    "\n",
    "      ###pythonだとmetadataはsource(ファイル名)のみで詳細箇所が不明なため、以下のログは意味なし\n",
    "      #for i in range(len(context_docs)):\n",
    "        #current_doc = context_docs[i] # i[0..len-1] のドキュメント\n",
    "        #logging.info(f\"i = {i}\")\n",
    "        #logging.info(f\"metadata = {current_doc.metadata}\") # ドキュメントのメタデータ\n",
    "        #logging.info(current_doc.page_content) # ドキュメントの中身\n",
    "\n",
    "      # 6. QAチェーンの初期化・エージェント化\n",
    "      print('\\n***エージェントが要約を実行***')\n",
    "      #https://qiita.com/mashmoeiar11/items/214984400e3452615ea5\n",
    "      # RetrievalQAの引数やAgent化\n",
    "      qa =RetrievalQA.from_chain_type(\n",
    "          llm=ChatOpenAI(model_name=GPT_MODEL),\n",
    "          chain_type=\"stuff\",\n",
    "          retriever=retriever,\n",
    "          chain_type_kwargs=chain_type_kwargs\n",
    "      )\n",
    "      tools = [\n",
    "          Tool(\n",
    "              name=\"vec_search\",\n",
    "              func=qa.run,\n",
    "              description=\"vector search result with\" + file_path\n",
    "          ),\n",
    "      ]\n",
    "      chat_agent = initialize_agent(\n",
    "        tools,\n",
    "        llm=ChatOpenAI(model_name=GPT_MODEL),\n",
    "        agent = \"zero-shot-react-description\",\n",
    "        verbose=True,\n",
    "        system_message=\"あなたは親切なアシスタントです。日本語で回答してください!\",\n",
    "      )\n",
    "      result = chat_agent.run(question)\n",
    "      print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f7b99-3967-455a-beca-ab6e3f93d2db",
   "metadata": {
    "collapsed": false,
    "id": "4lAv-bNZlYcl",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "20240204 9:47\n",
    "\n",
    "Mounted at /content/drive\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> 営業保険料\n",
    "\n",
    "***エージェントが要約を実行***\n",
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "To summarize a section about the premium for operational insurance in about 100 characters, I need to search for relevant content in the provided Hoken1.txt document.\n",
    "\n",
    "Action: vec_search\n",
    "Action Input: 営業保険料に関わる箇所\n",
    "Observation: 営業保険料に関連する部分ですが、営業保険料とは、保険会社が保険商品を販売する際に設定する保険料のことで、以下の要素を考慮して決定されます。\n",
    "\n",
    "1. 計算基礎率（死亡率、利率、事業費率など）の決定\n",
    "2. 計算基礎率に基づいた保険料の試算\n",
    "3. 試算保険料が会社の方針や市場競争状況に適合しているかのテスト\n",
    "4. 各計算基礎率について将来的に現実的と思われるものを設定し、試算保険料に基づき配当率や利益目標のテストを行う\n",
    "5. 最終的な料率の計算と法的要件や他の種類との調和性をテストする\n",
    "\n",
    "営業保険料には、予定事業費として以下のような経費が含まれます。\n",
    "\n",
    "- 新契約費：新規契約の獲得に必要な経費\n",
    "- 維持費：保険契約の維持に必要な経費\n",
    "- 集金費：保険料の収納に必要な経費\n",
    "\n",
    "事業費は、保険商品ごとに異なり、販売経路や保険種類ごとにも事業費の体系が変わることがあります。また、保険金の支払方法によっても事業費は異なるため、それぞれの事業費を適切に分析し、商品ごとに負担すべき事業費を求めることが必要です。\n",
    "\n",
    "営業保険料を巡る議論では、解約率の変動が保険業務に与える影響、商品の特性が解約を誘引するかどうか、解約率の変動が収益性や健全性に与える影響なども検討されます。\n",
    "\n",
    "営業保険料の設定は、保険会社のリスク管理と収益性に大きく影響するため、慎重に行われます。また、保険料の設定は法規制や市場の競争条件にも合わせて行われるため、保険会社はこれらの要素を考慮した上で、適切な営業保険料を決定します。\n",
    "Thought:I have found a section of the text that describes the concept of operational insurance premium and the factors involved in its determination. To create a summary of about 100 characters, I will focus on the core idea presented in the observation.\n",
    "\n",
    "Thought: I need to condense the information into a succinct summary that captures the essence of operational insurance premiums.\n",
    "Final Answer: 営業保険料は保険商品販売のための保険会社が設定する料金です。\n",
    "\n",
    "> Finished chain.\n",
    "営業保険料は保険商品販売のための保険会社が設定する料金です。\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> [exit]\n",
    "\n",
    "----------------\n",
    "\n",
    "[385-134647042584576]-2024-02-04 00:14:35,911-[<ipython-input-3-a5eb14aa3f50>:20]-INFO-secret = kazu_act_openai\n",
    "[385-134647042584576]-2024-02-04 00:14:41,245-[<ipython-input-3-a5eb14aa3f50>:109]-INFO-#docs = 183\n",
    "[385-134647042584576]-2024-02-04 00:14:41,245-[<ipython-input-3-a5eb14aa3f50>:124]-INFO-GPT_MODEL = gpt-4-1106-preview\n",
    "[385-134647042584576]-2024-02-04 00:14:41,245-[<ipython-input-3-a5eb14aa3f50>:125]-INFO-EMBEDDING_MODEL = text-embedding-3-large\n",
    "[385-134647042584576]-2024-02-04 00:14:42,082-[posthog.py:20]-INFO-Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
    "[385-134647042584576]-2024-02-04 00:14:42,244-[base.py:277]-WARNING-Warning: model not found. Using cl100k_base encoding.\n",
    "[385-134647042584576]-2024-02-04 00:14:58,291-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:15:24,725-[<ipython-input-3-a5eb14aa3f50>:157]-INFO-retrieval_query = 営業保険料に関わる箇所を抽出してください。\n",
    "[385-134647042584576]-2024-02-04 00:15:24,725-[<ipython-input-3-a5eb14aa3f50>:158]-INFO-question = 営業保険料に関わる箇所を1つ選択して100字程度に要約してください。\n",
    "[385-134647042584576]-2024-02-04 00:15:24,725-[<ipython-input-3-a5eb14aa3f50>:159]-INFO-prompt_qa = input_variables=['context', 'question'] template='あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\\n      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\\n      に答えてください。\\n\\n      {context}\\n\\n      質問: {question}\\n      回答（日本語）:'\n",
    "[385-134647042584576]-2024-02-04 00:15:24,725-[<ipython-input-3-a5eb14aa3f50>:160]-INFO-chain_type_kwargs = {'prompt': PromptTemplate(input_variables=['context', 'question'], template='あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\\n      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\\n      に答えてください。\\n\\n      {context}\\n\\n      質問: {question}\\n      回答（日本語）:')}\n",
    "[385-134647042584576]-2024-02-04 00:15:24,727-[base.py:277]-WARNING-Warning: model not found. Using cl100k_base encoding.\n",
    "[385-134647042584576]-2024-02-04 00:15:24,926-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:15:24,989-[<ipython-input-3-a5eb14aa3f50>:164]-INFO-#context_docs = 4\n",
    "[385-134647042584576]-2024-02-04 00:15:25,000-[<ipython-input-3-a5eb14aa3f50>:169]-INFO-#tokens_context_docs = 5398\n",
    "[385-134647042584576]-2024-02-04 00:15:27,687-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:15:27,692-[base.py:277]-WARNING-Warning: model not found. Using cl100k_base encoding.\n",
    "[385-134647042584576]-2024-02-04 00:15:27,847-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:15:56,564-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:16:00,991-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:16:45,740-[<ipython-input-4-9e6d633add65>:20]-INFO-secret = kazu_act_openai\n",
    "[385-134647042584576]-2024-02-04 00:16:47,015-[<ipython-input-4-9e6d633add65>:109]-INFO-#docs = 183\n",
    "[385-134647042584576]-2024-02-04 00:16:47,015-[<ipython-input-4-9e6d633add65>:124]-INFO-GPT_MODEL = gpt-4-1106-preview\n",
    "[385-134647042584576]-2024-02-04 00:16:47,015-[<ipython-input-4-9e6d633add65>:125]-INFO-EMBEDDING_MODEL = text-embedding-ada-002\n",
    "[385-134647042584576]-2024-02-04 00:17:00,569-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[385-134647042584576]-2024-02-04 00:17:53,621-[<ipython-input-5-9e6d633add65>:20]-INFO-secret = kazu_act_openai\n",
    "[385-134647042584576]-2024-02-04 00:17:54,803-[<ipython-input-5-9e6d633add65>:109]-INFO-#docs = 183\n",
    "[385-134647042584576]-2024-02-04 00:17:54,803-[<ipython-input-5-9e6d633add65>:124]-INFO-GPT_MODEL = gpt-4-1106-preview\n",
    "[385-134647042584576]-2024-02-04 00:17:54,803-[<ipython-input-5-9e6d633add65>:125]-INFO-EMBEDDING_MODEL = text-embedding-ada-002\n",
    "[385-134647042584576]-2024-02-04 00:18:07,934-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:42:40,045-[<ipython-input-2-9e6d633add65>:20]-INFO-secret = kazu_act_openai\n",
    "[8828-134245136535552]-2024-02-04 00:42:45,386-[<ipython-input-2-9e6d633add65>:109]-INFO-#docs = 183\n",
    "[8828-134245136535552]-2024-02-04 00:42:45,386-[<ipython-input-2-9e6d633add65>:124]-INFO-GPT_MODEL = gpt-4-1106-preview\n",
    "[8828-134245136535552]-2024-02-04 00:42:45,386-[<ipython-input-2-9e6d633add65>:125]-INFO-EMBEDDING_MODEL = text-embedding-ada-002\n",
    "[8828-134245136535552]-2024-02-04 00:42:46,335-[posthog.py:20]-INFO-Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
    "[8828-134245136535552]-2024-02-04 00:42:59,694-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:43:16,782-[<ipython-input-2-9e6d633add65>:157]-INFO-retrieval_query = 営業保険料に関わる箇所を抽出してください。\n",
    "[8828-134245136535552]-2024-02-04 00:43:16,782-[<ipython-input-2-9e6d633add65>:158]-INFO-question = 営業保険料に関わる箇所を1つ選択して100字程度に要約してください。\n",
    "[8828-134245136535552]-2024-02-04 00:43:16,782-[<ipython-input-2-9e6d633add65>:159]-INFO-prompt_qa = input_variables=['context', 'question'] template='あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\\n      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\\n      に答えてください。\\n\\n      {context}\\n\\n      質問: {question}\\n      回答（日本語）:'\n",
    "[8828-134245136535552]-2024-02-04 00:43:16,782-[<ipython-input-2-9e6d633add65>:160]-INFO-chain_type_kwargs = {'prompt': PromptTemplate(input_variables=['context', 'question'], template='あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\\n      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\\n      に答えてください。\\n\\n      {context}\\n\\n      質問: {question}\\n      回答（日本語）:')}\n",
    "[8828-134245136535552]-2024-02-04 00:43:16,998-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:43:17,037-[<ipython-input-2-9e6d633add65>:164]-INFO-#context_docs = 4\n",
    "[8828-134245136535552]-2024-02-04 00:43:17,043-[<ipython-input-2-9e6d633add65>:169]-INFO-#tokens_context_docs = 6429\n",
    "[8828-134245136535552]-2024-02-04 00:43:19,635-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:43:19,777-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:43:45,334-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:43:47,910-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:45:18,256-[<ipython-input-3-48aae7111bf7>:20]-INFO-secret = kazu_act_openai\n",
    "[8828-134245136535552]-2024-02-04 00:45:19,367-[<ipython-input-3-48aae7111bf7>:109]-INFO-#docs = 183\n",
    "[8828-134245136535552]-2024-02-04 00:45:19,367-[<ipython-input-3-48aae7111bf7>:124]-INFO-GPT_MODEL = gpt-4-1106-preview\n",
    "[8828-134245136535552]-2024-02-04 00:45:19,368-[<ipython-input-3-48aae7111bf7>:125]-INFO-EMBEDDING_MODEL = text-embedding-3-small\n",
    "[8828-134245136535552]-2024-02-04 00:45:19,500-[base.py:277]-WARNING-Warning: model not found. Using cl100k_base encoding.\n",
    "[8828-134245136535552]-2024-02-04 00:45:33,690-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,165-[<ipython-input-3-48aae7111bf7>:157]-INFO-retrieval_query = 営業保険料に関わる箇所を抽出してください。\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,165-[<ipython-input-3-48aae7111bf7>:158]-INFO-question = 営業保険料に関わる箇所を1つ選択して100字程度に要約してください。\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,165-[<ipython-input-3-48aae7111bf7>:159]-INFO-prompt_qa = input_variables=['context', 'question'] template='あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\\n      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\\n      に答えてください。\\n\\n      {context}\\n\\n      質問: {question}\\n      回答（日本語）:'\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,165-[<ipython-input-3-48aae7111bf7>:160]-INFO-chain_type_kwargs = {'prompt': PromptTemplate(input_variables=['context', 'question'], template='あなたは親切で優しいアシスタントです。丁寧に、日本語でお答えください！\\n      もし以下の情報が探している情報に関連していない場合は、そのトピックに関する自身の知識を用いて質問\\n      に答えてください。\\n\\n      {context}\\n\\n      質問: {question}\\n      回答（日本語）:')}\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,166-[base.py:277]-WARNING-Warning: model not found. Using cl100k_base encoding.\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,361-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,409-[<ipython-input-3-48aae7111bf7>:164]-INFO-#context_docs = 4\n",
    "[8828-134245136535552]-2024-02-04 00:45:51,415-[<ipython-input-3-48aae7111bf7>:169]-INFO-#tokens_context_docs = 5949\n",
    "[8828-134245136535552]-2024-02-04 00:45:55,354-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
    "[8828-134245136535552]-2024-02-04 00:45:55,359-[base.py:277]-WARNING-Warning: model not found. Using cl100k_base encoding.\n",
    "[8828-134245136535552]-2024-02-04 00:45:55,495-[_client.py:1027]-INFO-HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942b4ad-232e-4126-947e-99fc18bfd7bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860,
     "referenced_widgets": [
      "c2535fd8046848ccad4861f869131274",
      "d603def132eb496eb58c505903685bf7",
      "bee2185331964279ad72347eacf0af12",
      "8e88acb66a284e7e9692d6cb41253d78",
      "f37bf87138384488a42688fde9ed4420",
      "1629d8d5161145dcbc6b0a41d014fb31",
      "fa4491e7bfa74b02b37e5aaeac053139",
      "76d86cd728a0447cb9f81df9f6115641",
      "3a905afdabf9420d9bed801f7bb1c823",
      "f0d35fa695f141f1a517bb0c5a57b932",
      "54be2d640f9a48fe907d0bdc5aa5241a",
      "195bc420d21640098fa7819288fb4537",
      "ddda5cb4789c40179d86505694c97698",
      "84bdded0a69c4bd2be23879f87b16c1b",
      "5930d92e51384129a04f0ad00b42b039",
      "2f27b92aec384b01bf157b3c3d7143c5",
      "74d614a3a07443c28cb1c9d057433f36",
      "806a8e2fbba944ff80634249f2847dd9",
      "5fa9e69e509241288ccd227a06419610",
      "979f588d49ee4c70a0d2536954e3f905",
      "469d71d43a88402d8b21af6584d38dc0",
      "1ee268401fef4f59a151918eafe22519",
      "193bc3df53774d7593cd5d51ec1c5f5a",
      "759affa262834a7fbcc6e5061c1731ae",
      "d96fab1bf3334597a5a74a25dae5cd80",
      "4cddfa30f77b4a94a2facd5768fa797a",
      "6267962122464223b2a94fc5cf6726f8",
      "e97768440b1d4c54b2980e178b6d2a94",
      "c4c1cdb09a9f4ec092b498baf11c6cb9",
      "7acf7946a18e4bd0b2fbdff394e5cc9e",
      "4b00b72cb7c245d787542fa217085175",
      "d68d9e8ea2ec4e7e8c9b71efd7b18f9e",
      "bc8e05ab47f64da4bf85032206bc77ce",
      "cc073ea2dc6f4bd9b6d8c5b8491b8823",
      "0ad6432ddf444ddb92360ddbf05a7717",
      "7d12b4e9654b4002a51abb48a8b5e871",
      "ce7e4eac1fbe4422b037153b9c325c27",
      "b621995b435e45758efa124ff3f9dcf9",
      "e22768bbf4e74045abacab5ac93f6af2",
      "4141f217cb264c1da2083fad8c94ab26",
      "72357cd20d4741e4858b3fe01f0ebf9c",
      "d2034bc02cfb445b97ea8158e15684e2",
      "6961cc2df07541c2b7e85aeadf654bf0",
      "d05f297d40ad4da8afd87843b77d6f08",
      "b9123982efd24041ad8618f26e32c4b3",
      "e2d6b6af17fc4e5098b931cbc7585410",
      "0e6c1e37517e4486890fc406302b53b1",
      "a6ec2a9a89874889a91e5765dbf5d6bc",
      "fb275d3d3ef247509f2af98367b3ae7a",
      "7b99175fcf154eecbea79b89abd3dae5",
      "9d88aec9b82943a3b65b115ad2195275",
      "d0c72a0bd83949ad8b1e881e0252d99a",
      "9004f6e14d80446c8dd9e7623db01fc3",
      "8b28ec7642dd4af6a1501caf76bb47fb",
      "79907eaed53f4682912f56db6a54b6a5"
     ]
    },
    "collapsed": false,
    "id": "PsVcoNWSLMc4",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "1c0cee12-9d8d-486c-ce84-cad797cceb6c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# Shift_JISから逃れるための呪文なので気にしないでください\n",
    "#sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "#sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')\n",
    "\n",
    "def _input(prompt):\n",
    "    print(prompt, end='', flush=True)\n",
    "    #s = sys.stdin.buffer.readline()\n",
    "    s = input()\n",
    "#    s = s.decode('utf-8') \\\n",
    "    s = s.replace(\"\\r\", \"\") \\\n",
    "         .replace(\"\\n\", \"\")\n",
    "    return s\n",
    "\n",
    "# 公式のExampleを参考にしたプロンプト組み立て関数\n",
    "def make_prompt(log):\n",
    "    prompt = [\n",
    "        f\"{uttr['speaker']}: {uttr['text']}\"\n",
    "        for uttr in log\n",
    "    ]\n",
    "    prompt = \"<NL>\".join(prompt)\n",
    "    return prompt\n",
    "\n",
    "# 対話については辞書で持っておくようにする\n",
    "def add_log(log, role, text):\n",
    "    log.append({\n",
    "        \"speaker\": role,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "k = 40\n",
    "#max_length = 128\n",
    "max_length = 15\n",
    "\n",
    "\n",
    "# ちょっとずつ結果を出力してくれるジェネレータ。ChatGPTに聞きました、後述\n",
    "def gradually_generate(model, tokenizer, token_ids, max_length):\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(token_ids.to(model.device))\n",
    "\n",
    "        logits = outputs.logits\n",
    "        indices_to_remove = logits < torch.topk(logits, k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = float('-inf')\n",
    "        probs = torch.nn.functional.softmax(logits[..., -1, :], dim=-1)\n",
    "        next_token_id = torch.multinomial(probs, num_samples=1)\n",
    "        token_ids = torch.cat((token_ids, next_token_id), dim=-1)\n",
    "\n",
    "        output_str = tokenizer.decode(next_token_id[0])\n",
    "\n",
    "        yield output_str.replace(\"<NL>\", \"\\n\")\n",
    "\n",
    "        if \"</s>\" in output_str:\n",
    "            break\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"rinna/japanese-gpt-neox-3.6b-instruction-sft\", use_fast=False)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt-neox-3.6b-instruction-sft\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\", use_fast=False)\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
    "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
    "\n",
    "log = []\n",
    "\n",
    "while \"[exit]\" not in (user_message := _input(\"> \")):\n",
    "    add_log(log, \"ユーザー\", user_message)\n",
    "\n",
    "    prompt = (\n",
    "        make_prompt(log)\n",
    "        + \"<NL>\"\n",
    "        + \"システム: \"\n",
    "    )\n",
    "\n",
    "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "    output = \"\"\n",
    "    for word in gradually_generate(model, tokenizer, token_ids, max_length):\n",
    "        print(word, end='', flush=True)\n",
    "        output += word\n",
    "    print()\n",
    "\n",
    "    add_log(log, \"システム\", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434fa97-cb39-4a9a-b0a4-dba595cbeac0",
   "metadata": {
    "collapsed": false,
    "id": "swjZ-vQA18vc",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "実行例の保存その２（保険1全体を読み込ませたバージョン）\n",
    "\n",
    "Mounted at /content/drive\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> 付加保険料\n",
    "\n",
    "***エージェントが要約を実行***\n",
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "To summarize a section about additional premiums, I need to find relevant content in the text file provided.\n",
    "\n",
    "Action: vec_search\n",
    "Action Input: 付加保険料に関する箇所\n",
    "Observation: 付加保険料に関する箇所について、ご質問があればお答えします。付加保険料とは、保険会社が保険契約の運営に必要な経費を賄うために保険料に上乗せする部分のことを指します。その設定に関しては、保険業法施行規則の改正により、事前認可型から事後モニタリング型の監督体制へと変更されました。これにより、保険会社は収支の十分性や公平性を満たすことを前提とし、各自の責任と判断で付加保険料を設定することになりました。また、事業費関連の収支状況を定期的に測定し、主務官庁へモニタリング報告することが義務付けられています。特に新契約時にかかる費用（イニシャル・コスト）の回収状況や、契約維持・管理のために支出する事業費（ランニング・コスト）の充足状況について、販売経路や保険種類ごとに区分して測定し、付加保険料の十分性や公平性が事後的に検証されることになります。\n",
    "\n",
    "このトピックに関して、もっと具体的な質問があればお知らせください。お手伝いできることがあれば嬉しいです。\n",
    "Thought:The provided text explains that additional premiums are part of the insurance premium that is added by insurance companies to cover the necessary expenses for managing an insurance contract. The method for setting these additional premiums has been changed from a pre-approval system to a post-monitoring system due to revisions in the Insurance Business Law Enforcement Regulations. Insurance companies are now responsible for setting these fees on their own, ensuring sufficiency and fairness of revenue and expenses. They are also obligated to regularly measure and report their financial status related to business expenses to the competent authority. The adequacy and fairness of the additional premiums are verified post-factum, taking into account the cost of acquiring new contracts (initial costs) and the cost of maintaining and managing contracts (running costs), differentiated by sales channels and types of insurance.\n",
    "Final Answer: 付加保険料は保険運営経費を賄うため保険料に上乗せされ、保険業法改正により設定が事後モニタリング型に変更された。保険会社は収支公平性を基に自己責任で設定し、事業費収支を定期的に主務官庁に報告する。\n",
    "\n",
    "> Finished chain.\n",
    "付加保険料は保険運営経費を賄うため保険料に上乗せされ、保険業法改正により設定が事後モニタリング型に変更された。保険会社は収支公平性を基に自己責任で設定し、事業費収支を定期的に主務官庁に報告する。\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> 変額年金\n",
    "\n",
    "***エージェントが要約を実行***\n",
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "To find a section related to variable annuities (変額年金) within the provided text file, I should utilize the vec_search tool to locate relevant passages.\n",
    "\n",
    "Action: vec_search\n",
    "Action Input: 変額年金\n",
    "Observation: 変額年金とは、加入者が支払う保険料を株式や債券などの投資商品に運用し、その運用成果によって年金額が変動する年金保険の一種です。加入者は自分のリスク許容度や運用方針に応じて、運用資産を選択することができます。投資の成果が良ければ年金額が増加しますが、悪ければ減少するリスクを持ちます。\n",
    "\n",
    "日本においては、金融商品取引法に基づく適切な説明と情報提供が求められており、変額年金契約を結ぶ際には投資リスクや手数料などについて充分な理解が必要です。また、運用状況に応じて定期的な見直しや資産配分の変更を行うことも可能です。\n",
    "\n",
    "変額年金は運用成果が保証されていないため、予定利率を設定する従来型の定額年金保険とは異なります。そのため、将来受け取る年金額が予測しにくいという特徴がありますが、一方でインフレリスクに対する保護や資産増加のチャンスもあります。\n",
    "\n",
    "利用者は、自身の退職後のライフプランや資産状況、市場の動向を考慮しながら、変額年金が適した商品であるかどうかを検討することが重要です。\n",
    "Thought:The provided excerpt explains variable annuities as a type of pension insurance where the annuity amount fluctuates based on the performance of investments made with the insurance premiums paid by the policyholder. Policyholders can select the assets they wish to invest in according to their risk tolerance and investment strategy. While there is a chance for the annuity amount to increase with good investment performance, there is also a risk of decrease. In Japan, proper explanation and information provision based on the Financial Instruments and Exchange Act are required when entering into a variable annuity contract, and it is necessary to fully understand investment risks and fees. Regular reviews and asset allocation changes are also possible based on the performance of the investments. Unlike fixed annuities with set interest rates, variable annuities do not guarantee investment outcomes, making the future annuity amount unpredictable. However, they offer protection against inflation risks and opportunities for asset growth. It is crucial for users to consider whether variable annuities are suitable for them, taking into account their post-retirement life plan, asset status, and market trends.\n",
    "\n",
    "Final Answer: 変額年金は投資成果による年金額の変動が特徴で、市場の動向を考慮しリスクを理解した上で選択する必要があります。日本では金融商品取引法に基づく説明と情報提供が必須です。\n",
    "\n",
    "> Finished chain.\n",
    "変額年金は投資成果による年金額の変動が特徴で、市場の動向を考慮しリスクを理解した上で選択する必要があります。日本では金融商品取引法に基づく説明と情報提供が必須です。\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> [exit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3fdbb-a42c-4162-925b-614becc5485b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "Mz2K4cBpKer0",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "dd4a1ec7-b25b-4658-b552-006de421440e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e3314-9649-429c-9985-3e40192277fe",
   "metadata": {
    "collapsed": false,
    "id": "AZjVmeDNOkA4",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "##https://zenn.dev/ohtaman/articles/run_webapp_on_colab\n",
    "PORT = 8000\n",
    "PATH = ''\n",
    "\n",
    "# 検証用に適当なサーバーを立ち上げておく\n",
    "!nohup python3 -m http.server $PORT > server.log 2>&1 &\n",
    "\n",
    "from google.colab import output\n",
    "output.serve_kernel_port_as_window(PORT, path=PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b42df-247c-4177-b9f2-383de2a2c1ca",
   "metadata": {
    "collapsed": false,
    "id": "xf-YJ7FQQcnE",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "https://qiita.com/Isaka-code/items/f45a9a8288710aa807d9\n",
    "https://note.com/npaka/n/n0fd7bd3ed27b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cba9f-b656-4b1b-863b-d030575c1a3c",
   "metadata": {
    "collapsed": false,
    "id": "JV3oqfPRHKrY",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## https://qiita.com/namn1125/items/bc81f12f7bcfb2494c9c\n",
    "\n",
    "prompt = [\n",
    "    {\n",
    "        \"speaker\": \"ユーザー\",\n",
    "        \"text\": \"日本のおすすめの観光地を教えてください。\"\n",
    "    },\n",
    "    {\n",
    "        \"speaker\": \"システム\",\n",
    "        \"text\": \"どの地域の観光地が知りたいですか？\"\n",
    "    },\n",
    "    {\n",
    "        \"speaker\": \"ユーザー\",\n",
    "        \"text\": \"渋谷の観光地を教えてください。\"\n",
    "    }\n",
    "]\n",
    "prompt = [\n",
    "    f\"{uttr['speaker']}: {uttr['text']}\"\n",
    "    for uttr in prompt\n",
    "]\n",
    "prompt = \"<NL>\".join(prompt)\n",
    "prompt = (\n",
    "    prompt\n",
    "    + \"<NL>\"\n",
    "    + \"システム: \"\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\", use_fast=False)\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
    "# モデル指定\n",
    "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
    "\n",
    "# 筆者環境ではCPUで計算させるので↓は走りません\n",
    "if torch.cuda.is_available():\n",
    "   model = model.to(\"cuda\")\n",
    "\n",
    "token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        do_sample=True,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "print('output_ids', output_ids)\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1):])\n",
    "\n",
    "print('output', output)\n",
    "\n",
    "output = output.replace(\"<nl>\", \"\\n\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de56243-6bf6-48f0-87ab-aebd613a2435",
   "metadata": {
    "collapsed": false,
    "id": "A_quTNSE0aR4",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "実行例の保存その１\n",
    "\n",
    "Mounted at /content/drive\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> 営業保険料\n",
    "\n",
    "***要約を実行***\n",
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "I need to find a section in the provided text that discusses the business insurance premium and summarize it in about 100 characters.\n",
    "Action: vec_search\n",
    "Action Input: 営業保険料に関わる箇所\n",
    "Observation: 営業保険料に関わる箇所については、以下の内容が記載されています。\n",
    "\n",
    "1.1 純保険料と営業保険料\n",
    "ここでは、純保険料が保険期間中における保険事故の発生を仮定した予定死亡率や予定利率を基に計算されたものであり、営業保険料は純保険料以外に保険会社の経営に必要な経費を加えたものであることが説明されています。\n",
    "\n",
    "1.2 営業保険料決定の際に考慮すべき点\n",
    "営業保険料の水準を決める際には、十分性、公平性、収益性などの点を考慮する必要があることが述べられています。\n",
    "\n",
    "1.3 営業保険料率決定の諸要素\n",
    "死亡率や利率など、営業保険料率を決定する上で重要な要素が説明されています。\n",
    "\n",
    "1.4 付加保険料\n",
    "事業費、安全割増と営業利益、付加保険料に対する監督など、付加保険料に関する詳細が記載されています。\n",
    "\n",
    "1.5 付加保険料方式とその考え方\n",
    "付加保険料の考え方や方式、解約価格との関係が述べられています。\n",
    "\n",
    "1.6 営業保険料の計算\n",
    "年払基準の営業保険料、月払基準の営業保険料、高額割引など、営業保険料の計算方法が記されています。\n",
    "\n",
    "1.7 米英における営業保険料の計算\n",
    "アメリカやイギリスにおける営業保険料の計算方法が紹介されています。\n",
    "\n",
    "1.8 保険料を巡る議論\n",
    "保険料率の細分化、販売チャネルの多様化と料率設定、生保商品の価格弾力性についての議論が展開されています。\n",
    "\n",
    "Appendixには期待値原則についてや細分化料率策定の方法などが記載されており、最後に参考文献が挙げられています。\n",
    "\n",
    "これらの内容は、特に断らない限り、有配当の個人保険の営業保険料に関して記述されたものです。\n",
    "Thought:I have identified several sections related to business insurance premiums. Now I will choose one and summarize it.\n",
    "Action: vec_search\n",
    "Action Input: 1.1 純保険料と営業保険料の要約\n",
    "Observation: 純保険料とは、保険期間中に発生すると仮定される保険事故（主に死亡）に基づいて計算される保険料で、予定死亡率や予定利率をもとに、予定された保険給付の支払いに必要な金額を計算したものです。ここでの「予定」は単に将来の基礎率を推測したものではなく、実際の死亡率や利率が変わったとしても追加の保険料を徴収しない「保証」された基礎率です。そのため、これらの予定率には安全割増分が含まれており、契約者への配当の資源ともなります。\n",
    "\n",
    "一方、営業保険料は、保険給付の対価としての純保険料に加えて、保険会社が保険事業を経営するために必要な経費を加えたものです。純保険料以外の部分を付加保険料と呼び、日本では通常これには会社経営に必要な諸経費のみが含まれますが、外国では営業利益や契約者配当の財源を含む場合もあります。\n",
    "Thought:Now that I have a summary of section 1.1, I will condense it into approximately 100 characters.\n",
    "Final Answer: 純保険料は予定死亡率に基づく保険料。営業保険料には経費等が加算される。\n",
    "\n",
    "> Finished chain.\n",
    "純保険料は予定死亡率に基づく保険料。営業保険料には経費等が加算される。\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> 付加保険料\n",
    "\n",
    "***要約を実行***\n",
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "To answer the question, I need to find a section in the provided text file that discusses additional premiums (付加保険料). I will use vec_search to locate the relevant information.\n",
    "\n",
    "Action: vec_search\n",
    "Action Input: 付加保険料に関する情報を探す\n",
    "Observation: 付加保険料とは、保険料のうちで保険会社の運営経費や利益を賄うために設定される部分であり、純保険料（リスクのみをカバーするための保険料）とは別に計算されます。2月に行われた保険業法施行規則の改正では、付加保険料の部分に大きな変更がありました。\n",
    "\n",
    "改正前は事前認可型の監督体制でしたが、改正後は事後モニタリング型の監督体制に変更されました。これにより、付加保険料の設定は、収支の十分性や公平性を満たすことを前提に、算出方法書の認可事項ではなく、各保険会社の責任と判断で設定することとされました。さらに、事業費関連の収支状況を定期的に測定し、主務官庁へのモニタリング報告が義務付けられました。\n",
    "\n",
    "モニタリングでは、新契約時にかかる費用（イニシャルコスト）の回収状況や、契約維持・管理のために支出する事業費（ランニングコスト）の充足状況について、販売経路や保険種類ごとに区分して測定し、これにより付加保険料の十分性や公平性が事後的に検証されます。\n",
    "\n",
    "付加保険料の考え方としては、十分性を考慮して設定されるべきであり、普遍性や公平性の問題、費用主義と効用主義の考え方をバランスよくミックスさせた方式が望まれます。また、実際の計算方法としては、過去にはP'=P(1+k)+cやα-β-γ方式などが用いられてきましたが、最近ではα-β-γ方式が広く採用されています。これは新契約費と維持費を経費に組み込んで計算される方式です。\n",
    "\n",
    "以上が、付加保険料に関する基本的な情報です。もし、さらに具体的な情報が必要であれば、お知らせいただければと思います。\n",
    "Thought:I have found a section that explains additional premiums and contains several details that need to be succinctly summarized within 100 characters.\n",
    "\n",
    "Final Answer: 付加保険料は保険運営経費や利益に充てる分。改正で設定は各社の責任となり、公平性や十分性を事後検証する。\n",
    "\n",
    "> Finished chain.\n",
    "付加保険料は保険運営経費や利益に充てる分。改正で設定は各社の責任となり、公平性や十分性を事後検証する。\n",
    "\n",
    "保険1教科書第1章から、箇所を特定するキーワードを入力してください（例；営業保険料）。終了は[exit]。\n",
    "> [exit]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "name": "RAG_try.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ad6432ddf444ddb92360ddbf05a7717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e22768bbf4e74045abacab5ac93f6af2",
      "placeholder": "​",
      "style": "IPY_MODEL_4141f217cb264c1da2083fad8c94ab26",
      "value": "config.json: 100%"
     }
    },
    "0e6c1e37517e4486890fc406302b53b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0c72a0bd83949ad8b1e881e0252d99a",
      "max": 1369713080,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9004f6e14d80446c8dd9e7623db01fc3",
      "value": 1369713080
     }
    },
    "1629d8d5161145dcbc6b0a41d014fb31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "193bc3df53774d7593cd5d51ec1c5f5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_759affa262834a7fbcc6e5061c1731ae",
       "IPY_MODEL_d96fab1bf3334597a5a74a25dae5cd80",
       "IPY_MODEL_4cddfa30f77b4a94a2facd5768fa797a"
      ],
      "layout": "IPY_MODEL_6267962122464223b2a94fc5cf6726f8"
     }
    },
    "195bc420d21640098fa7819288fb4537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddda5cb4789c40179d86505694c97698",
       "IPY_MODEL_84bdded0a69c4bd2be23879f87b16c1b",
       "IPY_MODEL_5930d92e51384129a04f0ad00b42b039"
      ],
      "layout": "IPY_MODEL_2f27b92aec384b01bf157b3c3d7143c5"
     }
    },
    "1ee268401fef4f59a151918eafe22519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f27b92aec384b01bf157b3c3d7143c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a905afdabf9420d9bed801f7bb1c823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4141f217cb264c1da2083fad8c94ab26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "469d71d43a88402d8b21af6584d38dc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b00b72cb7c245d787542fa217085175": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cddfa30f77b4a94a2facd5768fa797a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d68d9e8ea2ec4e7e8c9b71efd7b18f9e",
      "placeholder": "​",
      "style": "IPY_MODEL_bc8e05ab47f64da4bf85032206bc77ce",
      "value": " 153/153 [00:00&lt;00:00, 8.54kB/s]"
     }
    },
    "54be2d640f9a48fe907d0bdc5aa5241a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5930d92e51384129a04f0ad00b42b039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_469d71d43a88402d8b21af6584d38dc0",
      "placeholder": "​",
      "style": "IPY_MODEL_1ee268401fef4f59a151918eafe22519",
      "value": " 806k/806k [00:00&lt;00:00, 7.12MB/s]"
     }
    },
    "5fa9e69e509241288ccd227a06419610": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6267962122464223b2a94fc5cf6726f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6961cc2df07541c2b7e85aeadf654bf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72357cd20d4741e4858b3fe01f0ebf9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74d614a3a07443c28cb1c9d057433f36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "759affa262834a7fbcc6e5061c1731ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e97768440b1d4c54b2980e178b6d2a94",
      "placeholder": "​",
      "style": "IPY_MODEL_c4c1cdb09a9f4ec092b498baf11c6cb9",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "76d86cd728a0447cb9f81df9f6115641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79907eaed53f4682912f56db6a54b6a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7acf7946a18e4bd0b2fbdff394e5cc9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b99175fcf154eecbea79b89abd3dae5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d12b4e9654b4002a51abb48a8b5e871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72357cd20d4741e4858b3fe01f0ebf9c",
      "max": 799,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d2034bc02cfb445b97ea8158e15684e2",
      "value": 799
     }
    },
    "806a8e2fbba944ff80634249f2847dd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84bdded0a69c4bd2be23879f87b16c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fa9e69e509241288ccd227a06419610",
      "max": 805634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_979f588d49ee4c70a0d2536954e3f905",
      "value": 805634
     }
    },
    "8b28ec7642dd4af6a1501caf76bb47fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e88acb66a284e7e9692d6cb41253d78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0d35fa695f141f1a517bb0c5a57b932",
      "placeholder": "​",
      "style": "IPY_MODEL_54be2d640f9a48fe907d0bdc5aa5241a",
      "value": " 282/282 [00:00&lt;00:00, 18.9kB/s]"
     }
    },
    "9004f6e14d80446c8dd9e7623db01fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "979f588d49ee4c70a0d2536954e3f905": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d88aec9b82943a3b65b115ad2195275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6ec2a9a89874889a91e5765dbf5d6bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b28ec7642dd4af6a1501caf76bb47fb",
      "placeholder": "​",
      "style": "IPY_MODEL_79907eaed53f4682912f56db6a54b6a5",
      "value": " 1.37G/1.37G [00:17&lt;00:00, 86.8MB/s]"
     }
    },
    "b621995b435e45758efa124ff3f9dcf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9123982efd24041ad8618f26e32c4b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2d6b6af17fc4e5098b931cbc7585410",
       "IPY_MODEL_0e6c1e37517e4486890fc406302b53b1",
       "IPY_MODEL_a6ec2a9a89874889a91e5765dbf5d6bc"
      ],
      "layout": "IPY_MODEL_fb275d3d3ef247509f2af98367b3ae7a"
     }
    },
    "bc8e05ab47f64da4bf85032206bc77ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bee2185331964279ad72347eacf0af12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76d86cd728a0447cb9f81df9f6115641",
      "max": 282,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a905afdabf9420d9bed801f7bb1c823",
      "value": 282
     }
    },
    "c2535fd8046848ccad4861f869131274": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d603def132eb496eb58c505903685bf7",
       "IPY_MODEL_bee2185331964279ad72347eacf0af12",
       "IPY_MODEL_8e88acb66a284e7e9692d6cb41253d78"
      ],
      "layout": "IPY_MODEL_f37bf87138384488a42688fde9ed4420"
     }
    },
    "c4c1cdb09a9f4ec092b498baf11c6cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc073ea2dc6f4bd9b6d8c5b8491b8823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ad6432ddf444ddb92360ddbf05a7717",
       "IPY_MODEL_7d12b4e9654b4002a51abb48a8b5e871",
       "IPY_MODEL_ce7e4eac1fbe4422b037153b9c325c27"
      ],
      "layout": "IPY_MODEL_b621995b435e45758efa124ff3f9dcf9"
     }
    },
    "ce7e4eac1fbe4422b037153b9c325c27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6961cc2df07541c2b7e85aeadf654bf0",
      "placeholder": "​",
      "style": "IPY_MODEL_d05f297d40ad4da8afd87843b77d6f08",
      "value": " 799/799 [00:00&lt;00:00, 45.3kB/s]"
     }
    },
    "d05f297d40ad4da8afd87843b77d6f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0c72a0bd83949ad8b1e881e0252d99a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2034bc02cfb445b97ea8158e15684e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d603def132eb496eb58c505903685bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1629d8d5161145dcbc6b0a41d014fb31",
      "placeholder": "​",
      "style": "IPY_MODEL_fa4491e7bfa74b02b37e5aaeac053139",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "d68d9e8ea2ec4e7e8c9b71efd7b18f9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d96fab1bf3334597a5a74a25dae5cd80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7acf7946a18e4bd0b2fbdff394e5cc9e",
      "max": 153,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b00b72cb7c245d787542fa217085175",
      "value": 153
     }
    },
    "ddda5cb4789c40179d86505694c97698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74d614a3a07443c28cb1c9d057433f36",
      "placeholder": "​",
      "style": "IPY_MODEL_806a8e2fbba944ff80634249f2847dd9",
      "value": "spiece.model: 100%"
     }
    },
    "e22768bbf4e74045abacab5ac93f6af2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2d6b6af17fc4e5098b931cbc7585410": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b99175fcf154eecbea79b89abd3dae5",
      "placeholder": "​",
      "style": "IPY_MODEL_9d88aec9b82943a3b65b115ad2195275",
      "value": "model.safetensors: 100%"
     }
    },
    "e97768440b1d4c54b2980e178b6d2a94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0d35fa695f141f1a517bb0c5a57b932": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f37bf87138384488a42688fde9ed4420": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa4491e7bfa74b02b37e5aaeac053139": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb275d3d3ef247509f2af98367b3ae7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
